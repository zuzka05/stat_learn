{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuzka05/stat_learn/blob/resample_lab/ch05_resample_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2d635a",
      "metadata": {
        "id": "dc2d635a"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6dde3cef",
      "metadata": {
        "id": "6dde3cef"
      },
      "source": [
        "# Cross-Validation and the Bootstrap\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch05-resample-lab.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/intro-stat-learning/ISLP_labs/v2.2?labpath=Ch05-resample-lab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9fd4324",
      "metadata": {
        "id": "a9fd4324"
      },
      "source": [
        "In this lab, we explore the resampling techniques covered in this\n",
        "chapter. Some of the commands in this lab may take a while to run on\n",
        "your computer.\n",
        "\n",
        "We again begin by placing most of our imports at this top level."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ISLP\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UyvRNd3spTD",
        "outputId": "6d147222-111d-4397-d18c-8f09cab23eb4"
      },
      "id": "4UyvRNd3spTD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ISLP\n",
            "  Downloading ISLP-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from ISLP) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.11/dist-packages (from ISLP) (1.15.3)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.11/dist-packages (from ISLP) (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from ISLP) (5.4.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from ISLP) (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from ISLP) (1.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.11/dist-packages (from ISLP) (0.14.4)\n",
            "Collecting lifelines (from ISLP)\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pygam (from ISLP)\n",
            "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from ISLP) (2.6.0+cu124)\n",
            "Collecting pytorch-lightning (from ISLP)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting torchmetrics (from ISLP)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20->ISLP) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20->ISLP) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20->ISLP) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->ISLP) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13->ISLP) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13->ISLP) (24.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines->ISLP) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines->ISLP) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pygam->ISLP) (4.5.0)\n",
            "Collecting scipy>=0.9 (from ISLP)\n",
            "  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.7.1 (from ISLP)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning->ISLP) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning->ISLP) (4.13.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->ISLP)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->ISLP)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->ISLP)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->ISLP)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->ISLP)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->ISLP)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->ISLP)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->ISLP)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->ISLP)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->ISLP)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->ISLP)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->ISLP) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->ISLP) (1.3.0)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.17.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (75.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.3)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP) (3.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20->ISLP) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->ISLP) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
            "Downloading ISLP-0.4.0-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=3916c9499aaff09db3a8f9f62546b3fd47dbf7203d6596fc6f7d0f7c5aa42749\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, interface-meta, scipy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pygam, nvidia-cusolver-cu12, formulaic, autograd-gamma, lifelines, torchmetrics, pytorch-lightning, ISLP\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ISLP-0.4.0 autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0 lightning-utilities-0.14.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pygam-0.9.1 pytorch-lightning-2.5.1.post0 scipy-1.11.4 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force reinstall numpy and related packages\n",
        "#!pip uninstall -y numpy\n",
        "#!pip install numpy==1.24.4 --force-reinstall --no-binary :all:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "on-opHUvts-B",
        "outputId": "1cd482af-bb07-401d-9d28-0e7c08641ca5"
      },
      "id": "on-opHUvts-B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpy: filename=numpy-1.24.4-cp311-cp311-linux_x86_64.whl size=21072183 sha256=05ce7cdfa312640bcbc47809cdcf9a4400d25e2fbf1e38305b54780324090a81\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/87/e1/d120c4ee01ab9fcc2f6449b09292e36eeb5cf26e79865139ff\n",
            "Successfully built numpy\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pygam 0.9.1 requires numpy>=1.25; python_version >= \"3.9\" and python_version < \"3.13\", but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a76bd56d23154203baf8c397b2a6380f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ISLP --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hu8Po7uwlV2",
        "outputId": "c8ee9da9-e184-436a-8a1b-f1d7c7e942ae"
      },
      "id": "9hu8Po7uwlV2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ISLP in /usr/local/lib/python3.11/dist-packages (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1deb5cc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:13.493284Z",
          "iopub.status.busy": "2024-06-04T23:19:13.492950Z",
          "iopub.status.idle": "2024-06-04T23:19:14.143174Z",
          "shell.execute_reply": "2024-06-04T23:19:14.142882Z"
        },
        "lines_to_next_cell": 2,
        "id": "f1deb5cc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from ISLP import load_data\n",
        "from ISLP.models import (ModelSpec as MS,\n",
        "                         summarize,\n",
        "                         poly)\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa08b62",
      "metadata": {
        "id": "afa08b62"
      },
      "source": [
        "There are several new imports needed for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268c41b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.144884Z",
          "iopub.status.busy": "2024-06-04T23:19:14.144773Z",
          "iopub.status.idle": "2024-06-04T23:19:14.146541Z",
          "shell.execute_reply": "2024-06-04T23:19:14.146330Z"
        },
        "lines_to_next_cell": 2,
        "id": "268c41b3"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from sklearn.model_selection import \\\n",
        "     (cross_validate,\n",
        "      KFold,\n",
        "      ShuffleSplit)\n",
        "from sklearn.base import clone\n",
        "from ISLP.models import sklearn_sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c04f8e4",
      "metadata": {
        "id": "1c04f8e4"
      },
      "source": [
        "## The Validation Set Approach\n",
        "We explore the use of the validation set approach in order to estimate\n",
        "the test error rates that result from fitting various linear models on\n",
        "the  `Auto`  data set.\n",
        "\n",
        "We use the function `train_test_split()` to split\n",
        "the data into training and validation sets. As there are 392 observations,\n",
        "we split into two equal sets of size 196 using the\n",
        "argument `test_size=196`. It is generally a good idea to set a random seed\n",
        "when performing operations like this that contain an\n",
        "element of randomness, so that the results obtained can be reproduced\n",
        "precisely at a later time. We set the random seed of the splitter\n",
        "with the argument `random_state=0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f44ae0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.147809Z",
          "iopub.status.busy": "2024-06-04T23:19:14.147730Z",
          "iopub.status.idle": "2024-06-04T23:19:14.152606Z",
          "shell.execute_reply": "2024-06-04T23:19:14.152414Z"
        },
        "id": "22f44ae0"
      },
      "outputs": [],
      "source": [
        "Auto = load_data('Auto')\n",
        "Auto_train, Auto_valid = train_test_split(Auto,\n",
        "                                         test_size=196,\n",
        "                                         random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318fe69f",
      "metadata": {
        "id": "318fe69f"
      },
      "source": [
        "Now we can fit a linear regression using only the observations corresponding to the training set `Auto_train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c32e917",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.153847Z",
          "iopub.status.busy": "2024-06-04T23:19:14.153757Z",
          "iopub.status.idle": "2024-06-04T23:19:14.157537Z",
          "shell.execute_reply": "2024-06-04T23:19:14.157339Z"
        },
        "id": "0c32e917"
      },
      "outputs": [],
      "source": [
        "hp_mm = MS(['horsepower'])\n",
        "X_train = hp_mm.fit_transform(Auto_train)\n",
        "y_train = Auto_train['mpg']\n",
        "model = sm.OLS(y_train, X_train)\n",
        "results = model.fit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e883b8f",
      "metadata": {
        "id": "7e883b8f"
      },
      "source": [
        "We now use the `predict()` method of `results` evaluated on the model matrix for this model\n",
        "created using the validation data set. We also calculate the validation MSE of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ce4f85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.158717Z",
          "iopub.status.busy": "2024-06-04T23:19:14.158637Z",
          "iopub.status.idle": "2024-06-04T23:19:14.162177Z",
          "shell.execute_reply": "2024-06-04T23:19:14.161910Z"
        },
        "id": "86ce4f85",
        "outputId": "ffc2fdcf-d7c8-4acf-d5f7-033867f821d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23.61661706966988"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_valid = hp_mm.transform(Auto_valid)\n",
        "y_valid = Auto_valid['mpg']\n",
        "valid_pred = results.predict(X_valid)\n",
        "np.mean((y_valid - valid_pred)**2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2ecdee6",
      "metadata": {
        "id": "f2ecdee6"
      },
      "source": [
        "Hence our estimate for the validation MSE of  the linear regression\n",
        "fit is $23.62$.\n",
        "\n",
        "We can also estimate the validation error for\n",
        "higher-degree polynomial regressions. We first provide a function `evalMSE()` that takes a model string as well\n",
        "as a training and test set and returns the MSE on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a66a97",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.163466Z",
          "iopub.status.busy": "2024-06-04T23:19:14.163397Z",
          "iopub.status.idle": "2024-06-04T23:19:14.165323Z",
          "shell.execute_reply": "2024-06-04T23:19:14.165076Z"
        },
        "id": "50a66a97"
      },
      "outputs": [],
      "source": [
        "def evalMSE(terms,\n",
        "            response,\n",
        "            train,\n",
        "            test):\n",
        "\n",
        "   mm = MS(terms)\n",
        "   X_train = mm.fit_transform(train)\n",
        "   y_train = train[response]\n",
        "\n",
        "   X_test = mm.transform(test)\n",
        "   y_test = test[response]\n",
        "\n",
        "   results = sm.OLS(y_train, X_train).fit()\n",
        "   test_pred = results.predict(X_test)\n",
        "\n",
        "   return np.mean((y_test - test_pred)**2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a255779c",
      "metadata": {
        "id": "a255779c"
      },
      "source": [
        "Let’s use this function to estimate the validation MSE\n",
        "using linear, quadratic and cubic fits. We use the `enumerate()`  function\n",
        "here, which gives both the values and indices of objects as one iterates\n",
        "over a for loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49b6999",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.166563Z",
          "iopub.status.busy": "2024-06-04T23:19:14.166497Z",
          "iopub.status.idle": "2024-06-04T23:19:14.177198Z",
          "shell.execute_reply": "2024-06-04T23:19:14.176975Z"
        },
        "id": "d49b6999",
        "outputId": "5c5d7985-e5e8-44ae-a8c9-34031006d2b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([23.61661707, 18.76303135, 18.79694163])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MSE = np.zeros(3)\n",
        "for idx, degree in enumerate(range(1, 4)):\n",
        "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
        "                       'mpg',\n",
        "                       Auto_train,\n",
        "                       Auto_valid)\n",
        "MSE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d7b8fc1",
      "metadata": {
        "id": "9d7b8fc1"
      },
      "source": [
        "These error rates are $23.62, 18.76$, and $18.80$, respectively. If we\n",
        "choose a different training/validation split instead, then we\n",
        "can expect somewhat different errors on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac8bd54",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.178405Z",
          "iopub.status.busy": "2024-06-04T23:19:14.178321Z",
          "iopub.status.idle": "2024-06-04T23:19:14.188650Z",
          "shell.execute_reply": "2024-06-04T23:19:14.188432Z"
        },
        "id": "dac8bd54",
        "outputId": "16d2643f-e6aa-4894-df50-a8eb48d03370"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([20.75540796, 16.94510676, 16.97437833])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Auto_train, Auto_valid = train_test_split(Auto,\n",
        "                                          test_size=196,\n",
        "                                          random_state=3)\n",
        "MSE = np.zeros(3)\n",
        "for idx, degree in enumerate(range(1, 4)):\n",
        "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
        "                       'mpg',\n",
        "                       Auto_train,\n",
        "                       Auto_valid)\n",
        "MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f2c12d",
      "metadata": {
        "id": "61f2c12d"
      },
      "source": [
        "Using this split of the observations into a training set and a validation set,\n",
        "we find that the validation set error rates for the models with linear, quadratic, and cubic terms are $20.76$, $16.95$, and $16.97$, respectively.\n",
        "\n",
        "These results are consistent with our previous findings: a model that\n",
        "predicts `mpg` using a quadratic function of `horsepower`\n",
        "performs better than a model that involves only a linear function of\n",
        "`horsepower`, and there is no evidence of an improvement in using a cubic function of `horsepower`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22daa51",
      "metadata": {
        "id": "f22daa51"
      },
      "source": [
        "## Cross-Validation\n",
        "In theory, the cross-validation estimate can be computed for any generalized\n",
        "linear model.  {}\n",
        "In practice, however, the simplest way to cross-validate in\n",
        "Python is to use `sklearn`, which has a different interface or API\n",
        "than `statsmodels`, the code we have been using to fit GLMs.\n",
        "\n",
        "This is a problem which often confronts data scientists: \"I have a function to do task $A$, and need to feed it into something that performs task $B$, so that I can compute $B(A(D))$, where $D$ is my data.\" When $A$ and $B$ don’t naturally speak to each other, this\n",
        "requires the use of a *wrapper*.\n",
        "In the `ISLP` package,\n",
        "we provide\n",
        "a wrapper, `sklearn_sm()`, that enables us to easily use the cross-validation tools of `sklearn` with\n",
        "models fit by `statsmodels`.\n",
        "\n",
        "The class `sklearn_sm()`\n",
        "has  as its first argument\n",
        "a model from `statsmodels`. It can take two additional\n",
        "optional arguments: `model_str` which can be\n",
        "used to specify a formula, and `model_args` which should\n",
        "be a dictionary of additional arguments used when fitting\n",
        "the model. For example, to fit a logistic regression model\n",
        "we have to specify a `family` argument. This\n",
        "is passed as `model_args={'family':sm.families.Binomial()}`.\n",
        "\n",
        "Here is our wrapper in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601ae443",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.189993Z",
          "iopub.status.busy": "2024-06-04T23:19:14.189906Z",
          "iopub.status.idle": "2024-06-04T23:19:14.876368Z",
          "shell.execute_reply": "2024-06-04T23:19:14.876129Z"
        },
        "lines_to_next_cell": 0,
        "id": "601ae443",
        "outputId": "8dca8963-b8f6-4f11-9b58-a1431e6e719f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24.23151351792924"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hp_model = sklearn_sm(sm.OLS,\n",
        "                      MS(['horsepower']))\n",
        "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
        "cv_results = cross_validate(hp_model,\n",
        "                            X,\n",
        "                            Y,\n",
        "                            cv=Auto.shape[0])\n",
        "cv_err = np.mean(cv_results['test_score'])\n",
        "cv_err\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebadc35f",
      "metadata": {
        "id": "ebadc35f"
      },
      "source": [
        "The arguments to `cross_validate()` are as follows: an\n",
        "object with the appropriate `fit()`, `predict()`,\n",
        "and `score()` methods,  an\n",
        "array of features `X` and a response `Y`.\n",
        "We also included an additional argument `cv` to `cross_validate()`; specifying an integer\n",
        "$K$ results in $K$-fold cross-validation. We have provided a value\n",
        "corresponding to the total number of observations, which results in\n",
        "leave-one-out cross-validation (LOOCV). The `cross_validate()`  function produces a dictionary with several components;\n",
        "we simply want the cross-validated test score here (MSE), which is estimated to be 24.23."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f47b99",
      "metadata": {
        "id": "25f47b99"
      },
      "source": [
        "We can repeat this procedure for increasingly complex polynomial fits.\n",
        "To automate the process, we again\n",
        "use a for loop which iteratively fits polynomial\n",
        "regressions of degree 1 to 5, computes the\n",
        "associated cross-validation error, and stores it in the $i$th element\n",
        "of the vector `cv_error`. The variable `d` in the for loop\n",
        "corresponds to the degree of the polynomial. We begin by initializing the\n",
        "vector. This command may take a couple of seconds to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11226c85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:14.877800Z",
          "iopub.status.busy": "2024-06-04T23:19:14.877726Z",
          "iopub.status.idle": "2024-06-04T23:19:15.384419Z",
          "shell.execute_reply": "2024-06-04T23:19:15.384193Z"
        },
        "lines_to_next_cell": 0,
        "id": "11226c85",
        "outputId": "cdea9789-733f-41d1-d015-9d8f8a876a52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([24.23151352, 19.24821312, 19.33498406, 19.42443033, 19.03323827])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_error = np.zeros(5)\n",
        "H = np.array(Auto['horsepower'])\n",
        "M = sklearn_sm(sm.OLS)\n",
        "for i, d in enumerate(range(1,6)):\n",
        "    X = np.power.outer(H, np.arange(d+1))\n",
        "    M_CV = cross_validate(M,\n",
        "                          X,\n",
        "                          Y,\n",
        "                          cv=Auto.shape[0])\n",
        "    cv_error[i] = np.mean(M_CV['test_score'])\n",
        "cv_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a920ae",
      "metadata": {
        "id": "a3a920ae"
      },
      "source": [
        "As in Figure~\\ref{Ch5:cvplot}, we see a sharp drop in the estimated test MSE between the linear and\n",
        "quadratic fits, but then no clear improvement from using higher-degree polynomials.\n",
        "\n",
        "Above we introduced the `outer()`  method of the `np.power()`\n",
        "function.  The `outer()` method is applied to an operation\n",
        "that has two arguments, such as `add()`, `min()`, or\n",
        "`power()`.\n",
        "It has two arrays as\n",
        "arguments, and then forms a larger\n",
        "array where the operation is applied to each pair of elements of the\n",
        "two arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b64d97",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.385768Z",
          "iopub.status.busy": "2024-06-04T23:19:15.385690Z",
          "iopub.status.idle": "2024-06-04T23:19:15.387686Z",
          "shell.execute_reply": "2024-06-04T23:19:15.387484Z"
        },
        "id": "64b64d97",
        "outputId": "f16ebabb-109d-4c6c-ebd2-813d48696a3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 5,  7],\n",
              "       [ 7,  9],\n",
              "       [11, 13]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = np.array([3, 5, 9])\n",
        "B = np.array([2, 4])\n",
        "np.add.outer(A, B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71385c1b",
      "metadata": {
        "id": "71385c1b"
      },
      "source": [
        "In the CV example above, we used $K=n$, but of course we can also use $K<n$. The code is very similar\n",
        "to the above (and is significantly faster). Here we use `KFold()` to partition the data into $K=10$ random groups. We use `random_state` to set a random seed and initialize a vector `cv_error` in which we will store the CV errors corresponding to the\n",
        "polynomial fits of degrees one to five."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0f972f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.389014Z",
          "iopub.status.busy": "2024-06-04T23:19:15.388934Z",
          "iopub.status.idle": "2024-06-04T23:19:15.407438Z",
          "shell.execute_reply": "2024-06-04T23:19:15.407194Z"
        },
        "lines_to_next_cell": 0,
        "id": "ca0f972f",
        "outputId": "bba67967-baa4-4b51-b06a-28269114d626"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([24.20766449, 19.18533142, 19.27626666, 19.47848403, 19.13720581])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_error = np.zeros(5)\n",
        "cv = KFold(n_splits=10,\n",
        "           shuffle=True,\n",
        "           random_state=0) # use same splits for each degree\n",
        "for i, d in enumerate(range(1,6)):\n",
        "    X = np.power.outer(H, np.arange(d+1))\n",
        "    M_CV = cross_validate(M,\n",
        "                          X,\n",
        "                          Y,\n",
        "                          cv=cv)\n",
        "    cv_error[i] = np.mean(M_CV['test_score'])\n",
        "cv_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b234093",
      "metadata": {
        "id": "8b234093"
      },
      "source": [
        "Notice that the computation time is much shorter than that of LOOCV.\n",
        "(In principle, the computation time for LOOCV for a least squares\n",
        "linear model should be faster than for $K$-fold CV, due to the\n",
        "availability of the formula~(\\ref{Ch5:eq:LOOCVform})  for LOOCV;\n",
        "however, the generic `cross_validate()`  function does not make\n",
        "use of this formula.)  We still see little evidence that using cubic\n",
        "or higher-degree polynomial terms leads to a lower test error than simply\n",
        "using a quadratic fit."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4487a4",
      "metadata": {
        "id": "fb4487a4"
      },
      "source": [
        "The `cross_validate()` function is flexible and can take\n",
        "different splitting mechanisms as an argument. For instance, one can use the `ShuffleSplit()` funtion to implement\n",
        "the validation set approach just as easily as K-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080cdb29",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.408750Z",
          "iopub.status.busy": "2024-06-04T23:19:15.408677Z",
          "iopub.status.idle": "2024-06-04T23:19:15.413979Z",
          "shell.execute_reply": "2024-06-04T23:19:15.413762Z"
        },
        "lines_to_next_cell": 2,
        "id": "080cdb29",
        "outputId": "d4a3f7fe-035d-41f9-d17c-3cd2c415af21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([23.61661707])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation = ShuffleSplit(n_splits=1,\n",
        "                          test_size=196,\n",
        "                          random_state=0)\n",
        "results = cross_validate(hp_model,\n",
        "                         Auto.drop(['mpg'], axis=1),\n",
        "                         Auto['mpg'],\n",
        "                         cv=validation);\n",
        "results['test_score']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f4b4cf",
      "metadata": {
        "id": "b2f4b4cf"
      },
      "source": [
        "One can estimate the variability in the test error by running the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c46de2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.415225Z",
          "iopub.status.busy": "2024-06-04T23:19:15.415158Z",
          "iopub.status.idle": "2024-06-04T23:19:15.437526Z",
          "shell.execute_reply": "2024-06-04T23:19:15.437302Z"
        },
        "id": "7c46de2b",
        "outputId": "01b0e0c8-2077-4cdd-82a5-b8dda8ebd5e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23.802232661034168, 1.421845094109185)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation = ShuffleSplit(n_splits=10,\n",
        "                          test_size=196,\n",
        "                          random_state=0)\n",
        "results = cross_validate(hp_model,\n",
        "                         Auto.drop(['mpg'], axis=1),\n",
        "                         Auto['mpg'],\n",
        "                         cv=validation)\n",
        "results['test_score'].mean(), results['test_score'].std()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07165f0e",
      "metadata": {
        "id": "07165f0e"
      },
      "source": [
        "Note that this standard deviation is not a valid estimate of the\n",
        "sampling variability of the mean test score or the individual scores, since the randomly-selected training\n",
        "samples overlap and hence introduce correlations. But it does give an\n",
        "idea of the Monte Carlo variation\n",
        "incurred by picking different random folds.\n",
        "\n",
        "## The Bootstrap\n",
        "We illustrate the use of the bootstrap in the simple example\n",
        " {of Section~\\ref{Ch5:sec:bootstrap},}  as well as on an example involving\n",
        "estimating the accuracy of the linear regression model on the  `Auto`\n",
        "data set.\n",
        "### Estimating the Accuracy of a Statistic of Interest\n",
        "One of the great advantages of the bootstrap approach is that it can\n",
        "be applied in almost all situations. No complicated mathematical\n",
        "calculations are required. While there are several implementations\n",
        "of the bootstrap in Python, its use for estimating\n",
        "standard error is simple enough that we write our own function\n",
        "below for the case when our data is stored\n",
        "in a dataframe.\n",
        "\n",
        "To illustrate the bootstrap, we\n",
        "start with a simple example.\n",
        "The  `Portfolio`  data set in the `ISLP` package is described\n",
        "in Section~\\ref{Ch5:sec:bootstrap}. The goal is to estimate the\n",
        "sampling variance of the parameter $\\alpha$ given in formula~(\\ref{Ch5:min.var}).  We will\n",
        "create a function\n",
        "`alpha_func()`, which takes as input a dataframe `D` assumed\n",
        "to have columns `X` and `Y`, as well as a\n",
        "vector `idx` indicating which observations should be used to\n",
        "estimate\n",
        "$\\alpha$. The function then outputs the estimate for $\\alpha$ based on\n",
        "the selected observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b6d9b3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.438786Z",
          "iopub.status.busy": "2024-06-04T23:19:15.438714Z",
          "iopub.status.idle": "2024-06-04T23:19:15.441484Z",
          "shell.execute_reply": "2024-06-04T23:19:15.441268Z"
        },
        "lines_to_next_cell": 0,
        "id": "a4b6d9b3"
      },
      "outputs": [],
      "source": [
        "Portfolio = load_data('Portfolio')\n",
        "def alpha_func(D, idx):\n",
        "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
        "   return ((cov_[1,1] - cov_[0,1]) /\n",
        "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d50058e",
      "metadata": {
        "id": "9d50058e"
      },
      "source": [
        "This function returns an estimate for $\\alpha$\n",
        "based on applying the minimum\n",
        "    variance formula (\\ref{Ch5:min.var}) to the observations indexed by\n",
        "the argument `idx`.  For instance, the following command\n",
        "estimates $\\alpha$ using all 100 observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81498a11",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.442843Z",
          "iopub.status.busy": "2024-06-04T23:19:15.442765Z",
          "iopub.status.idle": "2024-06-04T23:19:15.445171Z",
          "shell.execute_reply": "2024-06-04T23:19:15.444944Z"
        },
        "id": "81498a11",
        "outputId": "6a07874f-0ce3-4dbd-a93b-f41d7f1368b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.57583207459283"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alpha_func(Portfolio, range(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f5d0aab",
      "metadata": {
        "id": "4f5d0aab"
      },
      "source": [
        "Next we randomly select\n",
        "100 observations from `range(100)`, with replacement. This is equivalent\n",
        "to constructing a new bootstrap data set and recomputing $\\hat{\\alpha}$\n",
        "based on the new data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fe1cb6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.446422Z",
          "iopub.status.busy": "2024-06-04T23:19:15.446354Z",
          "iopub.status.idle": "2024-06-04T23:19:15.448793Z",
          "shell.execute_reply": "2024-06-04T23:19:15.448579Z"
        },
        "lines_to_next_cell": 2,
        "id": "64fe1cb6",
        "outputId": "ceb8a075-7d2d-4b8d-9ac8-ff08ad7b4935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6074452469619004"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rng = np.random.default_rng(0)\n",
        "alpha_func(Portfolio,\n",
        "           rng.choice(100,\n",
        "                      100,\n",
        "                      replace=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a635fe",
      "metadata": {
        "id": "91a635fe"
      },
      "source": [
        "This process can be generalized to create a simple function `boot_SE()` for\n",
        "computing the bootstrap standard error for arbitrary\n",
        "functions that take only a data frame as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd16bbae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.450062Z",
          "iopub.status.busy": "2024-06-04T23:19:15.449992Z",
          "iopub.status.idle": "2024-06-04T23:19:15.451958Z",
          "shell.execute_reply": "2024-06-04T23:19:15.451742Z"
        },
        "lines_to_next_cell": 0,
        "id": "dd16bbae"
      },
      "outputs": [],
      "source": [
        "def boot_SE(func,\n",
        "            D,\n",
        "            n=None,\n",
        "            B=1000,\n",
        "            seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    first_, second_ = 0, 0\n",
        "    n = n or D.shape[0]\n",
        "    for _ in range(B):\n",
        "        idx = rng.choice(D.index,\n",
        "                         n,\n",
        "                         replace=True)\n",
        "        value = func(D, idx)\n",
        "        first_ += value\n",
        "        second_ += value**2\n",
        "    return np.sqrt(second_ / B - (first_ / B)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4e17ed",
      "metadata": {
        "id": "ac4e17ed"
      },
      "source": [
        "Notice the use of `_` as a loop variable in `for _ in range(B)`. This is often used if the value of the counter is\n",
        "unimportant and simply makes sure  the loop is executed `B` times.\n",
        "\n",
        "Let’s use our function to evaluate the accuracy of our\n",
        "estimate of $\\alpha$ using $B=1{,}000$ bootstrap replications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42b4585",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.453190Z",
          "iopub.status.busy": "2024-06-04T23:19:15.453118Z",
          "iopub.status.idle": "2024-06-04T23:19:15.631597Z",
          "shell.execute_reply": "2024-06-04T23:19:15.631370Z"
        },
        "id": "b42b4585",
        "outputId": "614291be-9138-4a6b-d5e4-9af22a98b145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09118176521277699"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alpha_SE = boot_SE(alpha_func,\n",
        "                   Portfolio,\n",
        "                   B=1000,\n",
        "                   seed=0)\n",
        "alpha_SE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5464d7",
      "metadata": {
        "id": "6c5464d7"
      },
      "source": [
        "The final output shows that the bootstrap estimate for ${\\rm SE}(\\hat{\\alpha})$ is $0.0912$.\n",
        "\n",
        "### Estimating the Accuracy of a Linear Regression Model\n",
        "The bootstrap approach can be used to assess the variability of the\n",
        "coefficient estimates and predictions from a statistical learning\n",
        "method. Here we use the bootstrap approach in order to assess the\n",
        "variability of the estimates for $\\beta_0$ and $\\beta_1$, the\n",
        "intercept and slope terms for the linear regression model that uses\n",
        "`horsepower` to predict `mpg` in the  `Auto`  data set. We\n",
        "will compare the estimates obtained using the bootstrap to those\n",
        "obtained using the formulas for ${\\rm SE}(\\hat{\\beta}_0)$ and\n",
        "${\\rm SE}(\\hat{\\beta}_1)$ described in Section~\\ref{Ch3:secoefsec}.\n",
        "\n",
        "To use our `boot_SE()` function, we must write a function (its\n",
        "first argument)\n",
        "that takes a data frame `D` and indices `idx`\n",
        "as its only arguments. But here we want to bootstrap a specific\n",
        "regression model, specified by a model formula and data. We show how\n",
        "to do this in a few simple steps.\n",
        "\n",
        "We start by writing a generic\n",
        "function `boot_OLS()` for bootstrapping a regression model that takes a formula to\n",
        "define the corresponding regression. We use the `clone()` function to\n",
        "make a copy of the formula that can be refit to the new dataframe. This means\n",
        "that any derived features such as those defined by `poly()`\n",
        "(which we will see shortly),\n",
        "will be re-fit on the resampled data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc11784",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.632802Z",
          "iopub.status.busy": "2024-06-04T23:19:15.632725Z",
          "iopub.status.idle": "2024-06-04T23:19:15.634450Z",
          "shell.execute_reply": "2024-06-04T23:19:15.634222Z"
        },
        "lines_to_next_cell": 0,
        "id": "6bc11784"
      },
      "outputs": [],
      "source": [
        "def boot_OLS(model_matrix, response, D, idx):\n",
        "    D_ = D.loc[idx]\n",
        "    Y_ = D_[response]\n",
        "    X_ = clone(model_matrix).fit_transform(D_)\n",
        "    return sm.OLS(Y_, X_).fit().params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6ea3ce",
      "metadata": {
        "id": "2a6ea3ce"
      },
      "source": [
        "This is not quite what is needed as the first argument to\n",
        "`boot_SE()`. The first two arguments which specify the model will not change in the\n",
        "bootstrap process, and we would like to *freeze* them.   The\n",
        "function `partial()` from the `functools` module  does precisely this: it takes a function\n",
        "as an argument, and freezes some of its arguments, starting from the\n",
        "left. We use it to freeze the first two model-formula arguments of `boot_OLS()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740cd50c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.635644Z",
          "iopub.status.busy": "2024-06-04T23:19:15.635575Z",
          "iopub.status.idle": "2024-06-04T23:19:15.637097Z",
          "shell.execute_reply": "2024-06-04T23:19:15.636867Z"
        },
        "lines_to_next_cell": 0,
        "id": "740cd50c"
      },
      "outputs": [],
      "source": [
        "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6d19e2",
      "metadata": {
        "id": "ed6d19e2"
      },
      "source": [
        "Typing `hp_func?` will show that it has two arguments `D`\n",
        "and `idx` --- it is a version of `boot_OLS()` with the first\n",
        "two arguments frozen --- and hence is ideal as the first argument for `boot_SE()`.\n",
        "\n",
        "The `hp_func()` function can now be used in order to create\n",
        "bootstrap estimates for the intercept and slope terms by randomly\n",
        "sampling from among the observations with replacement. We first\n",
        "demonstrate its utility on 10 bootstrap samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb3ec50",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.638287Z",
          "iopub.status.busy": "2024-06-04T23:19:15.638220Z",
          "iopub.status.idle": "2024-06-04T23:19:15.656475Z",
          "shell.execute_reply": "2024-06-04T23:19:15.656261Z"
        },
        "lines_to_next_cell": 0,
        "id": "ffb3ec50",
        "outputId": "edd17238-98f4-4ced-93bd-049cffd3a825"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[39.12226577, -0.1555926 ],\n",
              "       [37.18648613, -0.13915813],\n",
              "       [37.46989244, -0.14112749],\n",
              "       [38.56723252, -0.14830116],\n",
              "       [38.95495707, -0.15315141],\n",
              "       [39.12563927, -0.15261044],\n",
              "       [38.45763251, -0.14767251],\n",
              "       [38.43372587, -0.15019447],\n",
              "       [37.87581142, -0.1409544 ],\n",
              "       [37.95949036, -0.1451333 ]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rng = np.random.default_rng(0)\n",
        "np.array([hp_func(Auto,\n",
        "          rng.choice(Auto.index,\n",
        "                     392,\n",
        "                     replace=True)) for _ in range(10)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d09d96",
      "metadata": {
        "id": "c6d09d96"
      },
      "source": [
        "Next, we use the `boot_SE()` {}  function to compute the standard\n",
        "errors of 1,000 bootstrap estimates for the intercept and slope terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d561f70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:15.657733Z",
          "iopub.status.busy": "2024-06-04T23:19:15.657659Z",
          "iopub.status.idle": "2024-06-04T23:19:17.204871Z",
          "shell.execute_reply": "2024-06-04T23:19:17.204614Z"
        },
        "lines_to_next_cell": 2,
        "id": "7d561f70",
        "outputId": "4e08448e-d117-40ba-de7b-8827bab6f8eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "intercept     0.731176\n",
              "horsepower    0.006092\n",
              "dtype: float64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hp_se = boot_SE(hp_func,\n",
        "                Auto,\n",
        "                B=1000,\n",
        "                seed=10)\n",
        "hp_se\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a834f240",
      "metadata": {
        "id": "a834f240"
      },
      "source": [
        "This indicates that the bootstrap estimate for ${\\rm SE}(\\hat{\\beta}_0)$ is\n",
        "0.85, and that the bootstrap\n",
        "estimate for ${\\rm SE}(\\hat{\\beta}_1)$ is\n",
        "0.0074.  As discussed in\n",
        "Section~\\ref{Ch3:secoefsec}, standard formulas can be used to compute\n",
        "the standard errors for the regression coefficients in a linear\n",
        "model. These can be obtained using the `summarize()`  function\n",
        "from `ISLP.sm`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3888aa0a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:17.206302Z",
          "iopub.status.busy": "2024-06-04T23:19:17.206223Z",
          "iopub.status.idle": "2024-06-04T23:19:17.221631Z",
          "shell.execute_reply": "2024-06-04T23:19:17.221444Z"
        },
        "lines_to_next_cell": 2,
        "id": "3888aa0a",
        "outputId": "faa3efaf-dd8e-4b66-acc8-fa1414d78804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "intercept     0.717\n",
              "horsepower    0.006\n",
              "Name: std err, dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hp_model.fit(Auto, Auto['mpg'])\n",
        "model_se = summarize(hp_model.results_)['std err']\n",
        "model_se\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aefc0575",
      "metadata": {
        "id": "aefc0575"
      },
      "source": [
        "The standard error estimates for $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$\n",
        "obtained using the formulas  from Section~\\ref{Ch3:secoefsec}  are\n",
        "0.717 for the\n",
        "intercept and\n",
        "0.006 for the\n",
        "slope. Interestingly, these are somewhat different from the estimates\n",
        "obtained using the bootstrap.  Does this indicate a problem with the\n",
        "bootstrap? In fact, it suggests the opposite.  Recall that the\n",
        "standard formulas given in\n",
        " {Equation~\\ref{Ch3:se.eqn} on page~\\pageref{Ch3:se.eqn}}\n",
        "rely on certain assumptions. For example,\n",
        "they depend on the unknown parameter $\\sigma^2$, the noise\n",
        "variance. We then estimate $\\sigma^2$ using the RSS. Now although the\n",
        "formula for the standard errors do not rely on the linear model being\n",
        "correct, the estimate for $\\sigma^2$ does.  We see\n",
        " {in Figure~\\ref{Ch3:polyplot} on page~\\pageref{Ch3:polyplot}}  that there is\n",
        "a non-linear relationship in the data, and so the residuals from a\n",
        "linear fit will be inflated, and so will $\\hat{\\sigma}^2$.  Secondly,\n",
        "the standard formulas assume (somewhat unrealistically) that the $x_i$\n",
        "are fixed, and all the variability comes from the variation in the\n",
        "errors $\\epsilon_i$.  The bootstrap approach does not rely on any of\n",
        "these assumptions, and so it is likely giving a more accurate estimate\n",
        "of the standard errors of $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ than\n",
        "the results from `sm.OLS`.\n",
        "\n",
        "Below we compute the bootstrap standard error estimates and the\n",
        "standard linear regression estimates that result from fitting the\n",
        "quadratic model to the data. Since this model provides a good fit to\n",
        "the data (Figure~\\ref{Ch3:polyplot}), there is now a better\n",
        "correspondence between the bootstrap estimates and the standard\n",
        "estimates of ${\\rm SE}(\\hat{\\beta}_0)$, ${\\rm SE}(\\hat{\\beta}_1)$ and\n",
        "${\\rm SE}(\\hat{\\beta}_2)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc3e32c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:17.222887Z",
          "iopub.status.busy": "2024-06-04T23:19:17.222785Z",
          "iopub.status.idle": "2024-06-04T23:19:19.351574Z",
          "shell.execute_reply": "2024-06-04T23:19:19.351317Z"
        },
        "id": "acc3e32c",
        "outputId": "8048b646-2354-4469-99ed-7e01bc69b0a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "intercept                                  1.538641\n",
              "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
              "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
              "dtype: float64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
        "quad_func = partial(boot_OLS,\n",
        "                    quad_model,\n",
        "                    'mpg')\n",
        "boot_SE(quad_func, Auto, B=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a2fd2b",
      "metadata": {
        "id": "e8a2fd2b"
      },
      "source": [
        "We  compare the results to the standard errors computed using `sm.OLS()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca5340c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-04T23:19:19.352904Z",
          "iopub.status.busy": "2024-06-04T23:19:19.352827Z",
          "iopub.status.idle": "2024-06-04T23:19:19.360147Z",
          "shell.execute_reply": "2024-06-04T23:19:19.359948Z"
        },
        "lines_to_next_cell": 0,
        "id": "dca5340c",
        "outputId": "01849f43-b622-438b-d610-c3c6d79979c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "intercept                                  1.800\n",
              "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
              "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
              "Name: std err, dtype: float64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "M = sm.OLS(Auto['mpg'],\n",
        "           quad_model.fit_transform(Auto))\n",
        "summarize(M.fit())['std err']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e98297be",
      "metadata": {
        "id": "e98297be"
      },
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}